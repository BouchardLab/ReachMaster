{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D  # noqa: F401 unused import\n",
    "from software.preprocessing.video_data.DLC.Reconstruction import dlt_reconstruct\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import shutil, os\n",
    "from PIL import Image\n",
    "from errno import EEXIST, ENOENT\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = ['10', '20', '30', '40', '50', '80', '90']\n",
    "\n",
    "prediction_csvs = {split: {} for split in splits}\n",
    "\n",
    "for split in splits:\n",
    "    prediction_csvs[split]['rm10'] = ['/Users/bassp/OneDrive/Desktop/Brett Stuff/Resnet101_AllCam_GroundTruths/Split_{}/ground_truths_C1_RM10DLC_resnet101_LabLabelOct27shuffle1_500000.csv'.format(split), 'C:/Users/bassp/OneDrive/Desktop/Brett Stuff/Resnet101_AllCam_GroundTruths/Split_{}/ground_truths_cam2_RM10DLC_resnet101_LabLabelOct27shuffle1_500000.csv'.format(split), 'C:/Users/bassp/OneDrive/Desktop/Brett Stuff/Resnet101_AllCam_GroundTruths/Split_{}/ground_truths_cam3_RM10DLC_resnet101_LabLabelOct27shuffle1_500000.csv'.format(split)]\n",
    "\n",
    "    prediction_csvs[split]['rm11'] = ['/Users/bassp/OneDrive/Desktop/Brett Stuff/Resnet101_AllCam_GroundTruths/Split_{}/ground_truths_cam1_RM11DLC_resnet101_LabLabelOct27shuffle1_500000.csv'.format(split), 'C:/Users/bassp/OneDrive/Desktop/Brett Stuff/Resnet101_AllCam_GroundTruths/Split_{}/ground_truths_cam2_RM11DLC_resnet101_LabLabelOct27shuffle1_500000.csv'.format(split), 'C:/Users/bassp/OneDrive/Desktop/Brett Stuff/Resnet101_AllCam_GroundTruths/Split_{}/ground_truths_cam3_RM11DLC_resnet101_LabLabelOct27shuffle1_500000.csv'.format(split)]\n",
    "\n",
    "    prediction_csvs[split]['rm13'] = ['/Users/bassp/OneDrive/Desktop/Brett Stuff/Resnet101_AllCam_GroundTruths/Split_{}/ground_truths_cam1_RM13DLC_resnet101_LabLabelOct27shuffle1_500000.csv'.format(split), 'C:/Users/bassp/OneDrive/Desktop/Brett Stuff/Resnet101_AllCam_GroundTruths/Split_{}/ground_truths_cam2_RM13DLC_resnet101_LabLabelOct27shuffle1_500000.csv'.format(split), 'C:/Users/bassp/OneDrive/Desktop/Brett Stuff/Resnet101_AllCam_GroundTruths/Split_{}/ground_truths_cam3_RM13DLC_resnet101_LabLabelOct27shuffle1_500000.csv'.format(split)]\n",
    "\n",
    "rm10_label_csvs = ['/Users/bassp/OneDrive/Desktop/Brett Stuff/March Labels/CollectedData_Lab_cam1_RM10.csv', '/Users/bassp/OneDrive/Desktop/Brett Stuff/March Labels/CollectedData_Lab_cam2_RM10.csv', '/Users/bassp/OneDrive/Desktop/Brett Stuff/March Labels/CollectedData_Lab_cam3_RM10.csv']\n",
    "rm11_label_csvs = ['/Users/bassp/OneDrive/Desktop/Brett Stuff/March Labels/CollectedData_Lab_cam1_RM11.csv', '/Users/bassp/OneDrive/Desktop/Brett Stuff/March Labels/CollectedData_Lab_cam2_RM11.csv', '/Users/bassp/OneDrive/Desktop/Brett Stuff/March Labels/CollectedData_Lab_cam3_RM11.csv']\n",
    "rm13_label_csvs = ['/Users/bassp/OneDrive/Desktop/Brett Stuff/March Labels/CollectedData_Lab_cam1_RM13.csv', '/Users/bassp/OneDrive/Desktop/Brett Stuff/March Labels/CollectedData_Lab_cam2_RM13.csv', '/Users/bassp/OneDrive/Desktop/Brett Stuff/March Labels/CollectedData_Lab_cam3_RM13.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_csv(prediction_csvs, label_csvs):\n",
    "    data_dict = {}\n",
    "    cam1_csv = np.loadtxt(label_csvs[0], dtype=str, delimiter=\",\")\n",
    "    names = cam1_csv[1,1::2].copy()\n",
    "\n",
    "    cam1_dlc_data = np.loadtxt(prediction_csvs[0], skiprows=3, delimiter=\",\")[:, 1:]\n",
    "    cam2_dlc_data = np.loadtxt(prediction_csvs[1], skiprows=3, delimiter=\",\")[:, 1:]\n",
    "    cam3_dlc_data = np.loadtxt(prediction_csvs[2], skiprows=3, delimiter=\",\")[:, 1:]\n",
    "\n",
    "    cam1_csv_data = np.genfromtxt(label_csvs[0], delimiter=\",\", skip_header=3, usecols=range(1, len(names)*2 + 1))\n",
    "    cam2_csv_data = np.genfromtxt(label_csvs[1], delimiter=\",\", skip_header=3, usecols=range(1, len(names)*2 + 1))\n",
    "    cam3_csv_data = np.genfromtxt(label_csvs[2], delimiter=\",\", skip_header=3, usecols=range(1, len(names)*2 + 1))\n",
    "\n",
    "    discarded = set()\n",
    "    shortest_len = min(cam1_dlc_data.shape[0], cam2_dlc_data.shape[0], cam3_dlc_data.shape[0])\n",
    "    for i in range(len(names)):\n",
    "        labelled_idx = i * 2\n",
    "        predicted_idx = i * 3\n",
    "        entry_dict = {}\n",
    "\n",
    "        cam1_labelled_x = cam1_csv_data[:shortest_len, labelled_idx].copy()\n",
    "        cam1_predicted_x = cam1_dlc_data[:shortest_len, predicted_idx].copy()\n",
    "        cam1_labelled_y = cam1_csv_data[:shortest_len, labelled_idx + 1].copy()\n",
    "        cam1_predicted_y = cam1_dlc_data[:shortest_len, predicted_idx + 1].copy()\n",
    "        cam1_predicted_prob = cam1_dlc_data[:shortest_len, predicted_idx + 2].copy()\n",
    "        \n",
    "        cam2_labelled_x = cam2_csv_data[:shortest_len, labelled_idx].copy()\n",
    "        cam2_predicted_x = cam2_dlc_data[:shortest_len, predicted_idx].copy()\n",
    "        cam2_labelled_y = cam2_csv_data[:shortest_len, labelled_idx + 1].copy()\n",
    "        cam2_predicted_y = cam2_dlc_data[:shortest_len, predicted_idx + 1].copy()\n",
    "        cam2_predicted_prob = cam2_dlc_data[:shortest_len, predicted_idx + 2].copy()\n",
    "\n",
    "        cam3_labelled_x = cam3_csv_data[:shortest_len, labelled_idx].copy()\n",
    "        cam3_predicted_x = cam3_dlc_data[:shortest_len, predicted_idx].copy()\n",
    "        cam3_labelled_y = cam3_csv_data[:shortest_len, labelled_idx + 1].copy()\n",
    "        cam3_predicted_y = cam3_dlc_data[:shortest_len, predicted_idx + 1].copy()\n",
    "        cam3_predicted_prob = cam3_dlc_data[:shortest_len, predicted_idx + 2].copy()\n",
    "\n",
    "\n",
    "        mask = np.isnan(cam1_labelled_x) | np.isnan(cam1_labelled_y) | np.isnan(cam2_labelled_x) | np.isnan(cam2_labelled_y) | np.isnan(cam3_labelled_x) | np.isnan(cam3_labelled_y)\n",
    "        if np.sum(~mask) < 10:\n",
    "            #print(\"Not enough entries for {}, discarding\".format(names[i]))\n",
    "            discarded.add(names[i])\n",
    "            continue\n",
    "        cam1_labelled_x[mask] = np.interp(np.flatnonzero(mask), np.flatnonzero(~mask), cam1_labelled_x[~mask])\n",
    "        cam1_labelled_y[mask] = np.interp(np.flatnonzero(mask), np.flatnonzero(~mask), cam1_labelled_y[~mask])\n",
    "        cam2_labelled_x[mask] = np.interp(np.flatnonzero(mask), np.flatnonzero(~mask), cam2_labelled_x[~mask])\n",
    "        cam2_labelled_y[mask] = np.interp(np.flatnonzero(mask), np.flatnonzero(~mask), cam2_labelled_y[~mask])\n",
    "        cam3_labelled_x[mask] = np.interp(np.flatnonzero(mask), np.flatnonzero(~mask), cam3_labelled_x[~mask])\n",
    "        cam3_labelled_y[mask] = np.interp(np.flatnonzero(mask), np.flatnonzero(~mask), cam3_labelled_y[~mask])\n",
    "        \n",
    "        entry_dict[\"Camera 1\"] = {}\n",
    "        entry_dict[\"Camera 1\"][\"labelled_x\"] = cam1_labelled_x\n",
    "        entry_dict[\"Camera 1\"][\"predicted_x\"] = cam1_predicted_x\n",
    "        entry_dict[\"Camera 1\"][\"labelled_y\"] = cam1_labelled_y\n",
    "        entry_dict[\"Camera 1\"][\"predicted_y\"] = cam1_predicted_y\n",
    "        entry_dict[\"Camera 1\"][\"predicted_prob\"] = cam1_predicted_prob\n",
    "        entry_dict[\"Camera 1\"][\"max_x\"] = max(np.max(entry_dict[\"Camera 1\"][\"labelled_x\"]), np.max(entry_dict[\"Camera 1\"][\"predicted_x\"]))\n",
    "        entry_dict[\"Camera 1\"][\"max_y\"] = max(np.max(entry_dict[\"Camera 1\"][\"labelled_y\"]), np.max(entry_dict[\"Camera 1\"][\"predicted_y\"]))\n",
    "        entry_dict[\"Camera 1\"][\"min_x\"] = min(np.min(entry_dict[\"Camera 1\"][\"labelled_x\"]), np.min(entry_dict[\"Camera 1\"][\"predicted_x\"]))\n",
    "        entry_dict[\"Camera 1\"][\"min_y\"] = min(np.min(entry_dict[\"Camera 1\"][\"labelled_y\"]), np.min(entry_dict[\"Camera 1\"][\"predicted_y\"]))\n",
    "\n",
    "        entry_dict[\"Camera 2\"] = {}\n",
    "        entry_dict[\"Camera 2\"][\"labelled_x\"] = cam2_labelled_x\n",
    "        entry_dict[\"Camera 2\"][\"predicted_x\"] = cam2_predicted_x\n",
    "        entry_dict[\"Camera 2\"][\"labelled_y\"] = cam2_labelled_y\n",
    "        entry_dict[\"Camera 2\"][\"predicted_y\"] = cam2_predicted_y\n",
    "        entry_dict[\"Camera 2\"][\"predicted_prob\"] = cam2_predicted_prob\n",
    "        entry_dict[\"Camera 2\"][\"max_x\"] = max(np.max(entry_dict[\"Camera 2\"][\"labelled_x\"]), np.max(entry_dict[\"Camera 2\"][\"predicted_x\"]))\n",
    "        entry_dict[\"Camera 2\"][\"max_y\"] = max(np.max(entry_dict[\"Camera 2\"][\"labelled_y\"]), np.max(entry_dict[\"Camera 2\"][\"predicted_y\"]))\n",
    "        entry_dict[\"Camera 2\"][\"min_x\"] = min(np.min(entry_dict[\"Camera 2\"][\"labelled_x\"]), np.min(entry_dict[\"Camera 2\"][\"predicted_x\"]))\n",
    "        entry_dict[\"Camera 2\"][\"min_y\"] = min(np.min(entry_dict[\"Camera 2\"][\"labelled_y\"]), np.min(entry_dict[\"Camera 2\"][\"predicted_y\"]))\n",
    "\n",
    "        entry_dict[\"Camera 3\"] = {}\n",
    "        entry_dict[\"Camera 3\"][\"labelled_x\"] = cam3_labelled_x\n",
    "        entry_dict[\"Camera 3\"][\"predicted_x\"] = cam3_predicted_x\n",
    "        entry_dict[\"Camera 3\"][\"labelled_y\"] = cam3_labelled_y\n",
    "        entry_dict[\"Camera 3\"][\"predicted_y\"] = cam3_predicted_y\n",
    "        entry_dict[\"Camera 3\"][\"predicted_prob\"] = cam3_predicted_prob\n",
    "        entry_dict[\"Camera 3\"][\"max_x\"] = max(np.max(entry_dict[\"Camera 3\"][\"labelled_x\"]), np.max(entry_dict[\"Camera 3\"][\"predicted_x\"]))\n",
    "        entry_dict[\"Camera 3\"][\"max_y\"] = max(np.max(entry_dict[\"Camera 3\"][\"labelled_y\"]), np.max(entry_dict[\"Camera 3\"][\"predicted_y\"]))\n",
    "        entry_dict[\"Camera 3\"][\"min_x\"] = min(np.min(entry_dict[\"Camera 3\"][\"labelled_x\"]), np.min(entry_dict[\"Camera 3\"][\"predicted_x\"]))\n",
    "        entry_dict[\"Camera 3\"][\"min_y\"] = min(np.min(entry_dict[\"Camera 3\"][\"labelled_y\"]), np.min(entry_dict[\"Camera 3\"][\"predicted_y\"]))\n",
    "        data_dict[names[i]] = entry_dict\n",
    "    filtered_names = [name for name in names if name not in discarded]\n",
    "    data_dict[\"filtered_names\"] = filtered_names\n",
    "    thres = 0.05\n",
    "    for name in filtered_names:\n",
    "        for cam in [\"Camera 1\", \"Camera 2\", \"Camera 3\"]:\n",
    "            mask = data_dict[name][cam][\"predicted_prob\"] < thres\n",
    "            data_dict[name][cam][\"interp_predicted_prob\"] = data_dict[name][cam][\"predicted_prob\"].copy()\n",
    "            data_dict[name][cam][\"interp_predicted_prob\"][mask] = np.interp(np.flatnonzero(mask), np.flatnonzero(~mask), data_dict[name][cam][\"predicted_prob\"][~mask])\n",
    "            data_dict[name][cam][\"interp_predicted_x\"] = data_dict[name][cam][\"predicted_x\"].copy()\n",
    "            data_dict[name][cam][\"interp_predicted_x\"][mask] = np.interp(np.flatnonzero(mask), np.flatnonzero(~mask), data_dict[name][cam][\"predicted_x\"][~mask])\n",
    "            data_dict[name][cam][\"interp_predicted_y\"] = data_dict[name][cam][\"predicted_y\"].copy()\n",
    "            data_dict[name][cam][\"interp_predicted_y\"][mask] = np.interp(np.flatnonzero(mask), np.flatnonzero(~mask), data_dict[name][cam][\"predicted_y\"][~mask])\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reconstructions(data_dict, dlt_coefs_file):\n",
    "    dlt_coefs = np.loadtxt(dlt_coefs_file, delimiter=\",\")\n",
    "    reconstructions = {}\n",
    "    for name in data_dict[\"filtered_names\"]:\n",
    "        # read in data from DLC\n",
    "        frames = data_dict[name][\"Camera 1\"][\"labelled_x\"].shape[0]\n",
    "        cam_data = np.empty([frames, 6], dtype=float)\n",
    "        weights = np.empty([frames, 6], dtype=float)\n",
    "\n",
    "        cam_data[:, 0] = data_dict[name][\"Camera 1\"][\"labelled_x\"]\n",
    "        cam_data[:, 1] = data_dict[name][\"Camera 1\"][\"labelled_y\"]\n",
    "        cam_data[:, 2] = data_dict[name][\"Camera 2\"][\"labelled_x\"]\n",
    "        cam_data[:, 3] = data_dict[name][\"Camera 2\"][\"labelled_y\"]\n",
    "        cam_data[:, 4] = data_dict[name][\"Camera 3\"][\"labelled_x\"]\n",
    "        cam_data[:, 5] = data_dict[name][\"Camera 3\"][\"labelled_y\"]\n",
    "\n",
    "        xyz_labelled = dlt_reconstruct(dlt_coefs, cam_data)\n",
    "\n",
    "        cam_data[:, 0] = data_dict[name][\"Camera 1\"][\"predicted_x\"]\n",
    "        cam_data[:, 1] = data_dict[name][\"Camera 1\"][\"predicted_y\"]\n",
    "        cam_data[:, 2] = data_dict[name][\"Camera 2\"][\"predicted_x\"]\n",
    "        cam_data[:, 3] = data_dict[name][\"Camera 2\"][\"predicted_y\"]\n",
    "        cam_data[:, 4] = data_dict[name][\"Camera 3\"][\"predicted_x\"]\n",
    "        cam_data[:, 5] = data_dict[name][\"Camera 3\"][\"predicted_y\"]\n",
    "        \n",
    "        weights[:, 0] = data_dict[name][\"Camera 1\"][\"predicted_prob\"]\n",
    "        weights[:, 1] = data_dict[name][\"Camera 1\"][\"predicted_prob\"]\n",
    "        weights[:, 2] = data_dict[name][\"Camera 2\"][\"predicted_prob\"]\n",
    "        weights[:, 3] = data_dict[name][\"Camera 2\"][\"predicted_prob\"]\n",
    "        weights[:, 4] = data_dict[name][\"Camera 3\"][\"predicted_prob\"]\n",
    "        weights[:, 5] = data_dict[name][\"Camera 3\"][\"predicted_prob\"]\n",
    "\n",
    "        xyz_predicted_weighted = dlt_reconstruct(dlt_coefs, cam_data, weights)\n",
    "        xyz_predicted_unweighted = dlt_reconstruct(dlt_coefs, cam_data)\n",
    "\n",
    "        cam_data[:, 0] = data_dict[name][\"Camera 1\"][\"interp_predicted_x\"]\n",
    "        cam_data[:, 1] = data_dict[name][\"Camera 1\"][\"interp_predicted_y\"]\n",
    "        cam_data[:, 2] = data_dict[name][\"Camera 2\"][\"interp_predicted_x\"]\n",
    "        cam_data[:, 3] = data_dict[name][\"Camera 2\"][\"interp_predicted_y\"]\n",
    "        cam_data[:, 4] = data_dict[name][\"Camera 3\"][\"interp_predicted_x\"]\n",
    "        cam_data[:, 5] = data_dict[name][\"Camera 3\"][\"interp_predicted_y\"]\n",
    "        \n",
    "        weights[:, 0] = data_dict[name][\"Camera 1\"][\"interp_predicted_prob\"]\n",
    "        weights[:, 1] = data_dict[name][\"Camera 1\"][\"interp_predicted_prob\"]\n",
    "        weights[:, 2] = data_dict[name][\"Camera 2\"][\"interp_predicted_prob\"]\n",
    "        weights[:, 3] = data_dict[name][\"Camera 2\"][\"interp_predicted_prob\"]\n",
    "        weights[:, 4] = data_dict[name][\"Camera 3\"][\"interp_predicted_prob\"]\n",
    "        weights[:, 5] = data_dict[name][\"Camera 3\"][\"interp_predicted_prob\"]\n",
    "\n",
    "        xyz_interp_predicted_weighted = dlt_reconstruct(dlt_coefs, cam_data, weights)\n",
    "        xyz_interp_predicted_unweighted = dlt_reconstruct(dlt_coefs, cam_data)\n",
    "\n",
    "        reconstructions[name] = {}\n",
    "        reconstructions[name][\"xyz_labelled\"] = xyz_labelled\n",
    "        reconstructions[name][\"xyz_predicted_weighted\"] = xyz_predicted_weighted\n",
    "        reconstructions[name][\"xyz_predicted_unweighted\"] = xyz_predicted_unweighted\n",
    "        reconstructions[name][\"xyz_interp_predicted_weighted\"] = xyz_interp_predicted_weighted\n",
    "        reconstructions[name][\"xyz_interp_predicted_unweighted\"] = xyz_interp_predicted_unweighted\n",
    "        reconstructions[name][\"xyz_predicted_prob\"] = np.mean(np.array([data_dict[name][\"Camera 1\"][\"predicted_prob\"], data_dict[name][\"Camera 2\"][\"predicted_prob\"], data_dict[name][\"Camera 3\"][\"predicted_prob\"]]), axis=0)\n",
    "        reconstructions[name][\"xyz_interp_predicted_prob\"] = np.mean(np.array([data_dict[name][\"Camera 1\"][\"interp_predicted_prob\"], data_dict[name][\"Camera 2\"][\"interp_predicted_prob\"], data_dict[name][\"Camera 3\"][\"interp_predicted_prob\"]]), axis=0)\n",
    "    return reconstructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dlt_coefs_file = '/Users/bassp/OneDrive/Desktop/Brett Stuff/DeepLabCutCSVs/test_dlt.csv'\n",
    "reconstructions = {}\n",
    "for split in splits:\n",
    "    rm10_data_dict = process_csv(prediction_csvs[split]['rm10'], rm10_label_csvs)\n",
    "    rm11_data_dict = process_csv(prediction_csvs[split]['rm11'], rm11_label_csvs)\n",
    "    rm13_data_dict = process_csv(prediction_csvs[split]['rm13'], rm13_label_csvs)\n",
    "   # pdb.set_trace()\n",
    "    rm10_reconstructions = get_reconstructions(rm10_data_dict, dlt_coefs_file)\n",
    "    rm11_reconstructions = get_reconstructions(rm11_data_dict, dlt_coefs_file)\n",
    "    rm13_reconstructions = get_reconstructions(rm13_data_dict, dlt_coefs_file)\n",
    "    reconstructions[split] = {'rm10':rm10_reconstructions, 'rm11':rm11_reconstructions, 'rm13':rm13_reconstructions}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mkdir_p(mypath):\n",
    "    '''Creates a directory. equivalent to using mkdir -p on the command line'''\n",
    "    try:\n",
    "        os.makedirs(mypath)\n",
    "    except OSError as exc: # Python >2.5\n",
    "        if exc.errno == EEXIST and os.path.isdir(mypath):\n",
    "            pass\n",
    "        else: raise\n",
    "\n",
    "def rm_dir(mypath):\n",
    "    '''Deletes a directory. equivalent to using rm -rf on the command line'''\n",
    "    try:\n",
    "        shutil.rmtree(mypath)\n",
    "    except OSError as exc: # Python >2.5\n",
    "        if exc.errno == ENOENT:\n",
    "            pass\n",
    "        else: raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm_dir('3d')\n",
    "def visualize_3D_data(reconstructions, split, data_type = \"xyz_labelled\"):\n",
    "    for rat in reconstructions[split].keys():\n",
    "        try:\n",
    "            xmax, ymax, zmax = np.max([np.max(reconstructions[split][rat][part][data_type], axis=0) for part in reconstructions[split][rat].keys()], axis=0)\n",
    "            xmin, ymin, zmin = np.min([np.min(reconstructions[split][rat][part][data_type], axis=0) for part in reconstructions[split][rat].keys()], axis=0)\n",
    "        except:\n",
    "            pdb.set_trace()\n",
    "        for i in range(reconstructions[split][rat][\"Handle\"][data_type].shape[0]):\n",
    "            if 'pred' in data_type:\n",
    "                output_dir = '3d/{}/predicted'.format(rat)\n",
    "            else:\n",
    "                output_dir = '3d/{}'.format(rat)\n",
    "            mkdir_p(output_dir)\n",
    "            fig = plt.figure()\n",
    "            ax = fig.add_subplot(111, projection='3d')\n",
    "            ax.set_xlim(xmax, xmin)\n",
    "            ax.set_ylim(ymax, ymin)\n",
    "            ax.set_zlim(zmax, zmin)\n",
    "            for name in reconstructions[split][rat].keys():\n",
    "                ax.scatter(*reconstructions[split][rat][name][data_type][i], label=name)\n",
    "            fig.legend()\n",
    "            filename='{}/3d_vis_rat_{}_frame{}.png'.format(output_dir, rat, i)\n",
    "            plt.savefig(filename, dpi=100)\n",
    "            plt.show()\n",
    "            #plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"xyz_interp_predicted_prob\"\n",
    "def ground_truth_3D(reconstructionss,split):\n",
    "    visualize_3D_data(reconstructionss,split)\n",
    "    for rat in reconstructionss[split].keys():\n",
    "        output_dir = '3d/{}'.format(rat)\n",
    "        png_count = len([name for name in os.listdir(output_dir) if os.path.isfile(os.path.join(output_dir, name))])\n",
    "        files = []\n",
    "        for i in range(png_count):\n",
    "            filename='{}/3d_vis_rat_{}_frame{}.png'.format(output_dir, rat, i)\n",
    "            files.append(filename)\n",
    "\n",
    "        frames = []\n",
    "        for i in files:\n",
    "            new_frame = Image.open(i)\n",
    "            frames.append(new_frame)\n",
    "\n",
    "        # Save into a GIF file that loops forever   \n",
    "        frames[0].save('{}/3d_vis_rat_{}.gif'.format('3d', rat), format='GIF',\n",
    "                    append_images=frames[1:],\n",
    "                    save_all=True,\n",
    "                    duration=40, loop=0)\n",
    "ground_truth_3D(reconstructions,split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp = \"xyz_interp_predicted_prob\"\n",
    "sll = \"xyz_predicted_prob\"\n",
    "\n",
    "def predicted_3D_gifs(reconstructions,split):\n",
    "    visualize_3D_data(reconstructions,split, data_type = \"xyz_predicted_prob\")\n",
    "    for rat in reconstructions[split].keys():\n",
    "        output_dir = '3d/{}/predicted'.format(rat)\n",
    "        png_count = len([name for name in os.listdir(output_dir) if os.path.isfile(os.path.join(output_dir, name))])\n",
    "        files = []\n",
    "        for i in range(png_count):\n",
    "            filename='{}/3d_vis_rat_{}_frame{}.png'.format(output_dir, rat, i)\n",
    "            files.append(filename)\n",
    "\n",
    "        frames = []\n",
    "        for i in files:\n",
    "            new_frame = Image.open(i)\n",
    "            frames.append(new_frame)\n",
    "\n",
    "        # Save into a GIF file that loops forever   \n",
    "        frames[0].save('{}/3d_vis_predicted_rat_{}.gif'.format('3d', rat), format='GIF',\n",
    "                    append_images=frames[1:],\n",
    "                    save_all=True,\n",
    "                    duration=40, loop=0)\n",
    "\n",
    "        \n",
    "predicted_3D_gifs(reconstructions,split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = {}\n",
    "for split in splits:\n",
    "    split_errors = {}\n",
    "    total_errors = {}\n",
    "    part_probabilities = {}\n",
    "    for rat, reconstruction in reconstructions[split].items():\n",
    "        rat_errors = []\n",
    "        for name in reconstruction.keys():\n",
    "            body_part_error = 1000 * mean_squared_error(reconstruction[name][\"xyz_labelled\"].T, reconstruction[name][\"xyz_predicted_weighted\"].T, squared=False, multioutput='raw_values')\n",
    "            rat_errors.append(body_part_error)\n",
    "            if total_errors.get(name) is None:\n",
    "                total_errors[name] = []\n",
    "                part_probabilities[name] = []\n",
    "            total_errors[name].extend(body_part_error)\n",
    "            part_probabilities[name].extend(reconstruction[name][\"xyz_predicted_prob\"])\n",
    "        split_errors[rat] = np.array(rat_errors)\n",
    "    errors[split] = {\"by_rat\" : split_errors, \"by_part\" : total_errors, \"part_prob\" : part_probabilities}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(50,7))\n",
    "ax = fig.add_subplot(111)\n",
    "start_pos = 1\n",
    "for i in range(len(splits)):\n",
    "    num_parts, _ = errors[splits[i]][\"by_rat\"]['rm10'].shape\n",
    "    ax.boxplot(errors[splits[i]][\"by_rat\"]['rm10'].T, positions=range(start_pos, start_pos + num_parts), labels=reconstructions[splits[i]]['rm10'].keys(), showfliers=False)\n",
    "    start_pos = start_pos + num_parts + 2\n",
    "ax.set_title(\"RMSE Distibution across Body Parts (Rat 10)\")\n",
    "fig.autofmt_xdate(rotation=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(50,7))\n",
    "ax = fig.add_subplot(111)\n",
    "start_pos = 1\n",
    "for i in range(len(splits)):\n",
    "    labels, data = errors[splits[i]][\"by_part\"].keys(), errors[splits[i]][\"by_part\"].values()\n",
    "    ax.boxplot(data, labels=labels, positions=range(start_pos, start_pos + len(labels)), showfliers=False)\n",
    "    start_pos = start_pos + len(labels) + 2\n",
    "ax.set_title(\"RMSE Distibution across Body Parts\")\n",
    "fig.autofmt_xdate(rotation=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_data = np.array([[np.mean(values) for values in errors[split][\"by_part\"].values()] for split in splits]).T\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "for i in range(len(splits)):\n",
    "    ax.plot(mean_data[:,i], label=splits[i])\n",
    "ax.legend()\n",
    "ax.set_title(\"Mean error per body part\")\n",
    "ax.set_xlabel(\"Body part\")\n",
    "ax.set_ylabel(\"Error (mm)\")\n",
    "ax.set_xticks(range(len(errors[split][\"by_part\"].keys())))\n",
    "ax.set_xticklabels(errors[split][\"by_part\"].keys())\n",
    "fig.autofmt_xdate(rotation=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for part in errors[split][\"by_part\"].keys():\n",
    "    fig = plt.figure(figsize=(50,7))\n",
    "    fig.suptitle(\"RMSE Split {} vs All Others ({})\".format(splits[-1], part))\n",
    "    for i in range(len(splits) - 1):\n",
    "        ax = fig.add_subplot(1, len(splits) - 1, i + 1)\n",
    "        x, y = np.array(errors[splits[-1]][\"by_part\"][part]), np.array(errors[splits[i]][\"by_part\"][part])\n",
    "        vmax = max(np.max(x), np.max(y))\n",
    "        pad = 0.1 * vmax\n",
    "        ax.set_ylim(0, vmax + pad)\n",
    "        ax.set_xlim(0, vmax + pad)\n",
    "        ax.set_aspect('equal')\n",
    "        ax.scatter(x, y, color='r')\n",
    "        ax.plot([ax.get_ylim()[0], ax.get_ylim()[1]],[ax.get_ylim()[0], ax.get_ylim()[1]],'k--', lw=1) # identity line\n",
    "        ax.set_title(\"Split {} vs Split {}\".format(splits[-1], splits[i]))\n",
    "        ax.set_ylabel(\"Split {} RMSE (mm)\".format(splits[i]))\n",
    "        ax.set_xlabel(\"Split {} RMSE (mm)\".format(splits[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for part in errors[split][\"by_part\"].keys():\n",
    "    fig = plt.figure(figsize=(50,7))\n",
    "    fig.suptitle(\"RMSE Split {} vs All Others ({})\".format(splits[-1], part))\n",
    "    for i in range(len(splits)):\n",
    "        ax = fig.add_subplot(1, len(splits), i + 1)\n",
    "        ax.set_ylim(0, 100)\n",
    "        x, y = np.array(errors[splits[i]][\"by_part\"][part]), 100 * np.array(errors[splits[i]][\"part_prob\"][part])\n",
    "        ax.scatter(x, y, color='r')\n",
    "        ax.set_title(\"RMSE vs Mean Camera Probability (Split {})\".format(splits[i]))\n",
    "        ax.set_ylabel(\"Probability\")\n",
    "        ax.set_xlabel(\"Split {} RMSE (mm)\".format(splits[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
